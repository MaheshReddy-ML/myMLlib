ğŸ¤– myMLlib â€“ Machine Learning from Scratch in Python
myMLlib is a growing collection of machine learning algorithms implemented from scratch in Python.
The goal is to make ML concepts clear, accessible, and customizable â€” while keeping the code clean and framework-free.

ğŸ“Œ Currently Includes
ğŸ“ˆ Linear Regression (Gradient Descent)

RÂ² Score, MSE metrics

Optional feature/target normalization

Plot regression fit

ğŸ“Š Logistic Regression (Binary Classification)

Binary Cross-Entropy (Log Loss)

Probability prediction (predict_proba)

Customizable decision threshold

Plot loss convergence

More algorithms (Decision Trees, KNN, Naive Bayes, etc.) coming soon ğŸš€

ğŸŒŸ Features
ğŸ“ Educational â€“ Learn ML by building it from scratch

âš™ï¸ Customizable â€“ Choose learning rate, epochs, normalization options, thresholds

ğŸ“¦ Lightweight â€“ Requires only Python, NumPy, Matplotlib

ğŸ” Metrics Included â€“ RÂ² Score, MSE, Log Loss

ğŸ“Š Visualizations â€“ Plot regression lines & loss curves

ğŸ“¦ Installation
Clone the repository and start using immediately:

bash
Copy
Edit
git clone https://github.com/MaheshReddy-ML/myMLlib.git
cd myMLlib
ğŸš€ Example Usage
Linear Regression:
from myMLlib import MyLinearRegression

X = [1, 2, 3, 4, 5]
y = [3, 4, 2, 5, 6]

model = MyLinearRegression(lr=0.01, epochs=1000)
model.fit(X, y)
predictions = model.predict([6, 7])

print("Predictions:", predictions)
print("RÂ² Score:", model.r2_score(y, model.predict(X)))

model.plot_fit(X, y)
Logistic Regression
from myMLlib import LogisticRegression

X = [0.1, 0.4, 0.5, 0.8, 1.2]
y = [0, 0, 1, 1, 1]

model = LogisticRegression(lr=0.1, epochs=2000)
model.fit(X, y)

print("Probabilities:", model.predict_proba([0.3, 0.9]))
print("Predictions:", model.predict([0.3, 0.9], threshold=0.5))
model.plot_loss()
